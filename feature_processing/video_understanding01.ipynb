{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import Markdown, clear_output, display, Video\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, AutoModel, AutoImageProcessor\n",
    "\n",
    "model_path = \"DAMO-NLP-SG/VideoLLaMA3-7B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def sample_frames_from_video(video_path, num_frames=64):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = total_frames // num_frames\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def display_frames_grid(frames, grid_size=(8, 8)):\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(16, 10))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(frames):\n",
    "            ax.imshow(frames[i])\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = '/ssd3/cheng/tabletennis/video1.mp4'\n",
    "# display(Video(video_path, width=576, height=1024, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "conversation = [\n",
    "    {        \n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"video\", \n",
    "                \"video\": {\"video_path\": video_path, \"fps\": 1, \"max_frames\": 180}\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe the landing point of a ping pong match \"\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Single-turn conversation\n",
    "inputs = processor(conversation=conversation, return_tensors=\"pt\")\n",
    "inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "if \"pixel_values\" in inputs:\n",
    "    inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.bfloat16)\n",
    "\n",
    "output_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "response = processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "display(Markdown(response))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add limition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "\n",
    "def generate_caption(video_path, video_height, video_width):\n",
    "    # You can display the video for debugging if needed\n",
    "    # display(Video(video_path, width=video_width, height=video_height, embed=True))\n",
    "    \n",
    "    conversation = [\n",
    "        {        \n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\", \n",
    "                    \"video\": {\"video_path\": video_path, \"fps\": 1, \"max_frames\": 180}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": \"Describe the video in detail.\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Single-turn conversation\n",
    "    inputs = processor(conversation=conversation, return_tensors=\"pt\")\n",
    "    inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "    if \"pixel_values\" in inputs:\n",
    "        inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.bfloat16)\n",
    "\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "    response = processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Load JSON data\n",
    "input_file = \"/ssd3/chunlin/smp_video_2025/test_data_combined/merged_data.json\"  # Update with your actual JSON file path\n",
    "with open(input_file, \"r\") as f:\n",
    "    json_data = f.readlines()\n",
    "\n",
    "# Parse each line as a separate JSON object\n",
    "video_data = []\n",
    "for line in json_data:\n",
    "    if line.strip():  # Skip empty lines\n",
    "        video_data.append(json.loads(line.strip()))\n",
    "\n",
    "# Initialize list to store caption results\n",
    "caption_results = []\n",
    "\n",
    "# Process each video\n",
    "for i, data in enumerate(video_data):\n",
    "    print(f\"Processing video {i+1}/{len(video_data)}: {data['vid']}\")\n",
    "    \n",
    "    # Extract necessary information\n",
    "    pid = data[\"pid\"]\n",
    "    uid = data[\"uid\"]\n",
    "    vid = data[\"vid\"]\n",
    "    video_path = data[\"video_path\"]\n",
    "    video_height = data[\"video_height\"]\n",
    "    video_width = data[\"video_width\"]\n",
    "    \n",
    "    try:\n",
    "        # Generate caption\n",
    "        caption = generate_caption(video_path, video_height, video_width)\n",
    "        \n",
    "        # Create result object\n",
    "        result = {\n",
    "            \"pid\": pid,\n",
    "            \"uid\": uid,\n",
    "            \"vid\": vid,\n",
    "            \"caption\": caption\n",
    "        }\n",
    "        \n",
    "        # Add to results\n",
    "        caption_results.append(result)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Caption generated for {vid}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {vid}: {str(e)}\")\n",
    "\n",
    "# Save results to caption.json\n",
    "output_file = \"caption.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    for result in caption_results:\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "print(f\"Captions saved to {output_file}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "#### prompt\n",
    "Q1, Q2: \"Describe the video in detail.\"(Q2 use limitation)  \n",
    "\n",
    "Q3: \"Based on the content of this TikTok video, determine its category from the following list: Dance, Comedy, Lip Sync, Tutorial, Beauty & Fashion, Fitness, Food & Drink, Pets & Animals, Vlogging, Challenges, Memes, Technology, Travel, Motivation & Inspiration, Art & Creativity, Sports, Music, Social Issues, Unboxing, Pranks, and Others. Provide a short explanation for your classification.\"  \n",
    "\n",
    "Q4: \"Provide a short description for this vedio.\"\n",
    "\n",
    "Q5: \"Analyze the video and provide detailed information about the subtitles or captions, including:\n",
    "- Whether subtitles are present or not.\n",
    "- The language(s) used in the subtitles.\n",
    "- The style of subtitles (e.g., font size, color, position, animation).\n",
    "- How subtitles contribute to the viewer's understanding and engagement.\n",
    "- Any noticeable timing or synchronization features with the spoken content.\n",
    "Please respond with concise bullet points.\"\n",
    "\n",
    "Q6: \"Based on the content, style, and context of the video, identify the most likely target audience by describing:\n",
    "- Age group(s) that would be interested.\n",
    "- Interests or hobbies relevant to the video.\n",
    "- Geographic or cultural background if identifiable.\n",
    "- Reasons or clues from the video that support your audience inference.\n",
    "Please provide your answer as brief bullet points.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_caption(video_path, retry_count=3):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(video_path):\n",
    "        return f\"ERROR: Video file not found: {video_path}\"\n",
    "    \n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            conversation = [\n",
    "                {        \n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"video\", \n",
    "                            \"video\": {\"video_path\": video_path, \"fps\": 1, \"max_frames\": 180}  # Reduced from 180\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\", \n",
    "                            \"text\": \"Analyze the video and provide detailed information about the subtitles or captions, including:- Whether subtitles are present or not.- The language(s) used in the subtitles.- The style of subtitles (e.g., font size, color, position, animation).- How subtitles contribute to the viewer's understanding and engagement.- Any noticeable timing or synchronization features with the spoken content.Please respond with concise bullet points.\"\n",
    "                        },\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            # Free up memory before processing\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process input\n",
    "            inputs = processor(conversation=conversation, return_tensors=\"pt\")\n",
    "            inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "            if \"pixel_values\" in inputs:\n",
    "                inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "            # Generate caption\n",
    "            output_ids = model.generate(**inputs, max_new_tokens=256)\n",
    "            response = processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "            \n",
    "            # Check if response is just repeating the prompt\n",
    "            if \"Describe the video in detail\" in response and len(response) < 50:\n",
    "                if attempt < retry_count - 1:\n",
    "                    print(f\"Attempt {attempt+1}: Got prompt repetition, retrying...\")\n",
    "                    time.sleep(random.uniform(3, 6))  # Random delay between retries\n",
    "                    continue\n",
    "                else:\n",
    "                    return \"ERROR: Model only returned the prompt after multiple attempts\"\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < retry_count - 1:\n",
    "                print(f\"Attempt {attempt+1} failed with error: {str(e)}, retrying...\")\n",
    "                time.sleep(random.uniform(2, 5))  # Random delay between retries\n",
    "            else:\n",
    "                return f\"ERROR: Failed after {retry_count} attempts. Last error: {str(e)}\"\n",
    "    \n",
    "    return \"ERROR: Failed to generate caption after multiple attempts\"\n",
    "\n",
    "\n",
    "# Load JSON data\n",
    "input_file = \"../processed_data/train_cleaned_data.json\"  # Update with your actual JSON file path\n",
    "output_file = \"caption_test_try.json\"\n",
    "checkpoint_file = \"caption_checkpoint.json\"  # To save progress periodically\n",
    "\n",
    "# Check if there's a checkpoint file to resume from\n",
    "processed_videos = set()\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    processed_videos.add(data[\"vid\"])\n",
    "                except:\n",
    "                    continue\n",
    "    print(f\"Resuming from checkpoint, {len(processed_videos)} videos already processed\")\n",
    "\n",
    "# Parse each line as a separate JSON object\n",
    "with open(input_file, \"r\") as f:\n",
    "    json_data = f.readlines()\n",
    "\n",
    "video_data = []\n",
    "for line in json_data:\n",
    "    if line.strip():  # Skip empty lines\n",
    "        try:\n",
    "            data = json.loads(line.strip())\n",
    "            if data[\"vid\"] not in processed_videos:\n",
    "                video_data.append(data)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f\"Found {len(video_data)} videos to process\")\n",
    "\n",
    "# Process each video with random delays to avoid overwhelming the system\n",
    "for i, data in enumerate(video_data):\n",
    "    try:\n",
    "        pid = data[\"pid\"]\n",
    "        uid = data[\"uid\"]\n",
    "        vid = data[\"vid\"]\n",
    "        video_path = data[\"video_path\"]\n",
    "        \n",
    "        print(f\"Processing {i+1}/{len(video_data)}: {vid}\")\n",
    "        \n",
    "        # Generate caption\n",
    "        caption = generate_caption(video_path)\n",
    "        \n",
    "        # Create result object\n",
    "        result = {\n",
    "            \"pid\": pid,\n",
    "            \"uid\": uid,\n",
    "            \"vid\": vid,\n",
    "            \"caption\": caption\n",
    "        }\n",
    "        \n",
    "        # Append to output file immediately to save progress\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "        # Also save to checkpoint\n",
    "        with open(checkpoint_file, \"a\") as f:\n",
    "            f.write(json.dumps(result) + \"\\n\")\n",
    "        \n",
    "        # Add random delay between processing videos\n",
    "        delay = random.uniform(1, 3)  # 1-3 seconds delay\n",
    "        print(f\"Waiting {delay:.2f} seconds before next video...\")\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        # Every 100 videos, do a longer cooldown to allow system recovery\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Completed {i+1} videos. Taking a longer break...\")\n",
    "            time.sleep(random.uniform(15, 30))  # 15-30 seconds cooldown\n",
    "            torch.cuda.empty_cache()  # Clear GPU cache\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video data: {str(e)}\")\n",
    "        # Still save the error to maintain the record\n",
    "        error_result = {\n",
    "            \"pid\": data.get(\"pid\", \"unknown\"),\n",
    "            \"uid\": data.get(\"uid\", \"unknown\"),\n",
    "            \"vid\": data.get(\"vid\", \"unknown\"),\n",
    "            \"caption\": f\"ERROR: Processing failed with error: {str(e)}\"\n",
    "        }\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(json.dumps(error_result) + \"\\n\")\n",
    "        with open(checkpoint_file, \"a\") as f:\n",
    "            f.write(json.dumps(error_result) + \"\\n\")\n",
    "\n",
    "print(f\"Caption generation completed. Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMPVideo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
